# -*- coding: utf-8 -*-
"""ProUNI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xf5O4Ql_Ea4ImRdJ7SaobTUZtdacPGyN

# EDA

An√°lise Explorat√≥ria

Equipe: Mateus Vinicius, Matheus Jos√©, Murilo Vinicius, Nicolas Roverato, Tiago Renan

1. Coleta de Dados
"""

!pip install geopandas geobr matplotlib
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import seaborn as sns
from geobr import read_state
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import numpy as np
import warnings
# Ignorar warnings de concatena√ß√£o/redefini√ß√£o de DataFrame
warnings.filterwarnings('ignore')

"""1.1 Carregando o conjunto de dados

1.2 Explorando a base com head(), info() e describe()
"""

# sep=';' porque o dataframe est√° separado por ,

def carregar_dados(caminho_arquivo:str) -> pd.DataFrame:
  return pd.read_csv("../content/pda-prouni-2017.csv", sep=';')

df_prouni = carregar_dados("../content/pda-prouni-2017.csv")

df_prouni.head()

df_prouni.info()

df_prouni.describe()

"""2. Limpeza e Prepara√ß√£o"""

def limpar_dados(df: pd.DataFrame) -> pd.DataFrame:

  # Remo√ß√£o de colunas

  colunas_para_remover = [
      'CODIGO_EMEC_IES_BOLSA',
      'CPF_BENEFICIARIO_BOLSA',
  ]

  df.drop(columns=colunas_para_remover, inplace=True)

  # Remo√ß√£o de linhas com valores ausentes

  df.dropna(inplace=True)


  # Renomear colunas

  df.rename(columns={
      'SIGLA_UF_BENEFICIARIO_BOLSA': 'UF_BENEFICIARIO_BOLSA',
      'MUNICIPIO_BENEFICIARIO_BOLSA':'MUNICIPIO',
      'REGIAO_BENEFICIARIO_BOLSA': 'REGIAO',
      'NOME_TURNO_CURSO_BOLSA': 'TURNO_CURSO'
  })

"""2.2 Removendo as colunas CPF e C√≥digo EMEC"""

colunas_para_remover = [
      'CODIGO_EMEC_IES_BOLSA',
      'CPF_BENEFICIARIO_BOLSA',
  ]

df_prouni.drop(columns=colunas_para_remover, inplace=True)

df_prouni.rename(columns={
      'SIGLA_UF_BENEFICIARIO_BOLSA': 'UF_BENEFICIARIO_BOLSA',
      'MUNICIPIO_BENEFICIARIO_BOLSA':'MUNICIPIO',
      'REGIAO_BENEFICIARIO_BOLSA': 'REGIAO',
      'NOME_TURNO_CURSO_BOLSA': 'TURNO_CURSO'
  }, inplace=True)

"""2.3 Descartando valores ausentes"""

# Removendo duplicatas
df_prouni.drop_duplicates(inplace=True)

df_prouni.dropna(inplace=True)

"""2.1 Convertendo DT_NASCIMENTO_BENEFICIARIO para formato datetime"""

# Convertendo DT_Nascimento para datetime

df_prouni['DT_NASCIMENTO_BENEFICIARIO'] = pd.to_datetime(
      df_prouni['DT_NASCIMENTO_BENEFICIARIO'], format='%d/%m/%Y', errors='coerce'
  )

# Preenchendo valores ausentes no campo idade com a moda

df_prouni['DT_NASCIMENTO_BENEFICIARIO'].fillna(
    df_prouni['DT_NASCIMENTO_BENEFICIARIO'].mode()[0],
    inplace=True
)

"""2.4 Calculando a idade dos beneficiarios"""

# Calculando ano de nascimento e idade

df_prouni['ANO_NASCIMENTO'] = df_prouni['DT_NASCIMENTO_BENEFICIARIO'].dt.year
df_prouni['IDADE_BENEFICIARIO'] = 2017 - df_prouni['ANO_NASCIMENTO']
df_prouni.drop(columns=['DT_NASCIMENTO_BENEFICIARIO', 'ANO_NASCIMENTO'], inplace=True)

# Removendo outliers da coluna idade
coluna = 'IDADE_BENEFICIARIO'

# 1. Calcular Q1, Q3 e IQR
# Q1: 25% dos dados est√£o abaixo deste valor
Q1 = df_prouni[coluna].quantile(0.25)
# Q3: 75% dos dados est√£o abaixo deste valor
Q3 = df_prouni[coluna].quantile(0.75)
IQR = Q3 - Q1

# 2. Definir os limites superior e inferior para os outliers
limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR

print(f"Outliers de {coluna} ser√£o removidos fora do intervalo: [{limite_inferior:.2f}, {limite_superior:.2f}]")

# 3. FILTRAGEM E REATRIBUI√á√ÉO (A√ß√£o 'in-place')
# Cria uma m√°scara booleana para as linhas DENTRO do intervalo aceit√°vel.
mascara = (df_prouni[coluna] >= limite_inferior) & (df_prouni[coluna] <= limite_superior)

# Sobrescreve o DataFrame original (df_prouni) apenas com as linhas que satisfazem a m√°scara.
# Usar .copy() √© recomendado para evitar o SettingWithCopyWarning
df_prouni = df_prouni[mascara].copy()

print(f"Registros removidos (outliers): {len(mascara) - len(df_prouni)}")
print(f"Novo tamanho do DataFrame: {len(df_prouni)}")

df_prouni.info()

"""2.5 Normaliza√ß√£o"""

# Codificando vari√°veis para valores bin√°rios

def codificar_variaveis_categoricas(df: pd.DataFrame) -> pd.DataFrame:

  colunas_para_codificar = [
      'TIPO_BOLSA',
      'BENEFICIARIO_DEFICIENTE_FISICO',
      'SEXO_BENEFICIARIO_BOLSA',
      'RACA_BENEFICIARIO_BOLSA',
      'MODALIDADE_ENSINO_BOLSA',
      'REGIAO',
  ]

  mapeamentos_sim_nao = {
      'S': 1,  # Sim
      'N': 0   # N√£o
  }
  mapeamentos_ead_presencial = {
      'EAD': 1,
      'Presencial': 0
  }

  # Aplica o mapeamento e renomeia as colunas para clareza
  if 'BENEFICIARIO_DEFICIENTE_FISICO' in df.columns:
      df['DEFICIENTE_BINARIO'] = df['BENEFICIARIO_DEFICIENTE_FISICO'].map(mapeamentos_sim_nao)
      df.drop(columns=['BENEFICIARIO_DEFICIENTE_FISICO'], inplace=True, errors='ignore')

  if 'MODALIDADE_ENSINO_BOLSA' in df.columns:
      df['MODALIDADE_EAD_BINARIO'] = df['MODALIDADE_ENSINO_BOLSA'].map(mapeamentos_ead_presencial)
      df.drop(columns=['MODALIDADE_ENSINO_BOLSA'], inplace=True, errors='ignore')

# Codifica√ß√£o 1 de c para colunas com mais de duas categorias

colunas_para_dummies = [
      'TIPO_BOLSA',
      'SEXO_BENEFICIARIO_BOLSA',
      'RACA_BENEFICIARIO_BOLSA',
      'NOME_TURNO_CURSO_BOLSA',
      'REGIAO_BENEFICIARIO_BOLSA'
  ]

# Filtra apenas as colunas que existem no DataFrame para evitar erros
colunas_existentes = [col for col in colunas_para_dummies if col in df_prouni.columns]

# Usa pd.get_dummies() que √© a forma mais eficiente de fazer One-Hot Encoding
# e j√° remove as colunas originais por padr√£o (drop_first=False)
df_prouni = pd.get_dummies(
    df_prouni,
    columns=colunas_existentes,
    prefix=colunas_existentes
)

print("\nCodifica√ß√£o 1 de c (One-Hot) e bin√°ria conclu√≠da.")

df_prouni.info()

# Removendo coluna ra√ßa n√£o informada

coluna_remover = 'RACA_BENEFICIARIO_BOLSA_N√£o Informada'

if coluna_remover in df_prouni.columns:
    df_prouni.drop(columns=[coluna_remover], inplace=True)

# Visualiza√ß√£o de Dados

# Repetir gr√°ficos aqui

df_prouni["NOME_CURSO_BOLSA"].value_counts()

"""3. An√°lise Descritiva

3.1 Calculando a m√©dia de idade dos bolsistas
"""

df_prouni["IDADE_BENEFICIARIO"].describe()

df_prouni['IDADE_BENEFICIARIO'].mean()

"""3.2 Pergunta: Qual institui√ß√£o mais concedeu bolsas?"""

df_prouni['NOME_IES_BOLSA'].value_counts().head()

"""4. Visualiza√ß√£o de Dados

4.1 Quais universidades concedem mais bolsas?
"""

top_universidades = df_prouni['NOME_IES_BOLSA'].value_counts().head()

mapeamento_nomes = {
    'UNIVERSIDADE PIT√ÅGORAS UNOPAR': 'UNOPAR',
    'UNIVERSIDADE EST√ÅCIO DE S√Å': 'EST√ÅCIO',
    'UNIVERSIDADE PAULISTA': 'UNIP',
    'UNIVERSIDADE NOVE DE JULHO': 'UNINOVE',
    'CENTRO UNIVERSIT√ÅRIO INTERNACIONAL': 'UNINTER',
    'PONTIF√çCIA UNIVERSIDADE CAT√ìLICA DE MINAS GERAIS': 'PUC MINAS',
}

nomes_universidades = top_universidades.index.map(lambda x: mapeamento_nomes.get(x, x))
valores = top_universidades.values

universidades_simplificadas = nomes_universidades[::-1]
valores_ordenados = valores[::-1]

plt.style.use('seaborn-v0_8-whitegrid')
plt.figure(figsize=(12, 6))

barras = plt.barh(universidades_simplificadas, valores_ordenados, color='#1f77b4')

plt.title("Top 5 Universidades com Mais Bolsas (Nomes Simplificados)", fontsize=16, pad=20)
plt.xlabel("N√∫mero de Bolsas Concedidas", fontsize=12)
plt.ylabel("Institui√ß√£o de Ensino Superior (IES)", fontsize=12)

for i, v in enumerate(valores_ordenados):
    plt.text(v + (valores_ordenados.max() * 0.01),
             i,
             str(v),
             color='black',
             va='center',
             fontsize=10)

plt.tight_layout()
plt.show()

"""5. An√°lise de distribui√ß√£o

5.1 Qual modalidade de ensino √© mais recorrente?
"""

dados_pizza = df_prouni['MODALIDADE_ENSINO_BOLSA'].value_counts()

labels = dados_pizza.index
sizes = dados_pizza.values


def func_autopct(pct):
    absolute = int(pct/100.*sizes.sum())
    return "{:.1f}%\n({:d})".format(pct, absolute)


plt.figure(figsize=(8, 8))

cores = ['#1f77b4', '#9467bd']


plt.pie(
    sizes,
    labels=labels,
    autopct=func_autopct,
    startangle=90,
    colors=cores,
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'},
    pctdistance=0.8
)


plt.title("Distribui√ß√£o de Bolsas por Modalidade de Ensino (PROUNI 2017)", fontsize=16, pad=20)
plt.axis('equal')
plt.tight_layout()
plt.show()

"""5.2 Quais cursos s√£o mais ofertados?"""

top_cursos = df_prouni['NOME_CURSO_BOLSA'].value_counts().head()

labels = top_cursos.index
sizes = top_cursos.values
total_bolsas = df_prouni['NOME_CURSO_BOLSA'].value_counts().sum()

cores = sns.color_palette('tab10')

def formatar_legenda_curso(label, size, total):
    pct = (size / total) * 100
    return f'{label} - {pct:.1f}% ({size:d})'

plt.figure(figsize=(10, 8))

wedges, texts = plt.pie(
    sizes,
    labels=None,
    autopct=None,
    startangle=90,
    colors=cores,
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'}
)

full_labels = [formatar_legenda_curso(label, size, total_bolsas) for label, size in zip(labels, sizes)]

plt.legend(
    wedges,
    full_labels,
    loc="center left",
    bbox_to_anchor=(1, 0, 0.5, 1),
    fontsize=10,
    title_fontsize=12
)

plt.axis('equal')
plt.tight_layout()
plt.show()

"""5.3 Qual a ra√ßa dos benefici√°rios?"""

def gerar_grafico_pizza_raca(df: pd.DataFrame):
    """
    Gera um gr√°fico de pizza para visualizar a distribui√ß√£o de bolsas por ra√ßa,
    utilizando as colunas bin√°rias resultantes do One-Hot Encoding.

    :param df: DataFrame com as colunas bin√°rias de Ra√ßa codificadas.
    """
    print("Gerando Gr√°fico de Pizza por Ra√ßa...")

    # 1. CORRE√á√ÉO: Nomes das colunas ap√≥s One-Hot Encoding
    # Utilizamos as colunas criadas por pd.get_dummies:
    colunas_raca = {
        'Parda': 'RACA_BENEFICIARIO_BOLSA_Parda',
        'Branca': 'RACA_BENEFICIARIO_BOLSA_Branca',
        'Preta': 'RACA_BENEFICIARIO_BOLSA_Preta',
        'Amarela': 'RACA_BENEFICIARIO_BOLSA_Amarela',
        'Ind√≠gena': 'RACA_BENEFICIARIO_BOLSA_Ind√≠gena'
    }

    # 2. CORRE√á√ÉO: Usar .sum() nas colunas bin√°rias e ordenar (como o c√≥digo original fazia)
    # A categoria 'N√£o Informada' √© intencionalmente omitida, como discutido.
    dados_pizza_raca = pd.Series({
        label: df[col].sum()
        for label, col in colunas_raca.items()
    }).sort_values(ascending=False)

    labels = dados_pizza_raca.index
    sizes = dados_pizza_raca.values
    total_bolsas = sizes.sum()

    # Define a paleta de cores para o gr√°fico
    cores = plt.cm.Set3.colors

    # Fun√ß√£o auxiliar para criar a legenda com % e contagem absoluta
    def formatar_legenda(label, size, total):
        pct = (size / total) * 100
        return f'{label} - {pct:.1f}% ({size:d})'

    # 3. Gera√ß√£o do Gr√°fico de Pizza
    plt.figure(figsize=(10, 10))

    # Plota a pizza sem labels internos (autopct=None)
    wedges, texts = plt.pie(
        sizes,
        labels=None,
        autopct=None,
        startangle=90,
        colors=cores,
        wedgeprops={'linewidth': 1, 'edgecolor': 'white'}
    )

    # Cria as strings da legenda completa
    full_labels = [formatar_legenda(label, size, total_bolsas) for label, size in zip(labels, sizes)]

    # Adiciona a legenda externa, crucial para gr√°ficos de pizza grandes
    plt.legend(
        wedges,
        full_labels,
        title="Ra√ßa do Benefici√°rio",
        loc="center left",
        bbox_to_anchor=(1, 0, 0.5, 1), # Posiciona a legenda √† direita
        fontsize=10,
        title_fontsize=12
    )

    plt.title("Distribui√ß√£o de Bolsas por Ra√ßa do Benefici√°rio (PROUNI 2017)", fontsize=16, pad=8)
    plt.axis('equal') # Garante que o gr√°fico seja um c√≠rculo
    plt.tight_layout()
    plt.show()

gerar_grafico_pizza_raca(df_prouni)

df_mapa = pd.read_csv(
    'pda-prouni-2017.csv',
    delimiter=';',
    usecols=['SIGLA_UF_BENEFICIARIO_BOLSA', 'TIPO_BOLSA']
)

bolsas_por_estado = (
    df_mapa
    .groupby('SIGLA_UF_BENEFICIARIO_BOLSA')
    .size()
    .reset_index(name='total_bolsas')
)


bolsas_por_estado.rename(
    columns={'SIGLA_UF_BENEFICIARIO_BOLSA': 'abbrev_state'},
    inplace=True
)

brasil = read_state()

mapa_bolsas = brasil.merge(bolsas_por_estado, on='abbrev_state', how='left')

mapa_bolsas['total_bolsas'] = mapa_bolsas['total_bolsas'].fillna(0)

fig, ax = plt.subplots(1,1,figsize=(12,10))

mapa_bolsas.plot(
    ax=ax,
    column='total_bolsas',
    cmap='YlOrRd',
    linewidth=0.8,
    edgecolor='0.8',
    legend=True,
    legend_kwds={
        'label':'Total scholarships¬†awarded',
        'orientation': "horizontal",
        'shrink': 0.5
    }
)

ax.set_axis_off()

plt.title("Choropleth map of ProUni scholarships (2017)", fontsize=16)
plt.show()

"""6. Detec√ß√£o de Outliers

6.1 Boxplot da idade dos benefici√°rios:
"""

def gerar_boxplot_idade(df: pd.DataFrame):
    """
    Gera um Boxplot para a coluna IDADE_BENEFICIARIO,
    permitindo visualizar a distribui√ß√£o, mediana e poss√≠veis outliers.

    :param df: DataFrame com a coluna IDADE_BENEFICIARIO.
    """
    coluna_idade = 'IDADE_BENEFICIARIO'

    if coluna_idade not in df.columns:
        print(f"Erro: A coluna '{coluna_idade}' n√£o foi encontrada no DataFrame.")
        return

    print(f"Gerando Boxplot para a coluna: {coluna_idade}")

    plt.figure(figsize=(10, 6))

    # 1. Usando Seaborn para gerar o Boxplot
    # 'y' define a coluna num√©rica
    # 'orient="h"' torna o boxplot horizontal, o que costuma ser mais limpo para uma √∫nica vari√°vel
    sns.boxplot(
        y=df[coluna_idade],
        orient='v',
        color='#4c72b0', # Cor azul padr√£o do Seaborn/Matplotlib
        width=0.4
    )

    # 2. Configura√ß√µes e T√≠tulos
    plt.title('Distribui√ß√£o da Idade dos Benefici√°rios (P√≥s-Limpeza IQR)', fontsize=16, pad=20)
    plt.ylabel('Idade do Benefici√°rio', fontsize=14)
    plt.yticks(fontsize=12)
    plt.grid(axis='y', linestyle='--', alpha=0.7) # Grade apenas no eixo Y para melhor leitura

    # Adiciona a Mediana (opcional, mas √∫til para o entendimento)
    mediana = df[coluna_idade].median()
    plt.axhline(mediana, color='red', linestyle='--', linewidth=2, label=f'Mediana: {mediana:.0f} anos')
    plt.legend()

    plt.show()

# ==============================================================================
# EXECU√á√ÉO (Exemplo)
# ==============================================================================

# Assumindo que o DataFrame 'df' est√° carregado e limpo:

gerar_boxplot_idade(df_prouni)

"""7. An√°lise de Correla√ß√£o

"""

# Recreate 'RACA_BENEFICIARIO_BOLSA' from dummy variables for crosstab
# This creates a temporary column for analysis without altering the main DataFrame structure
def get_race_from_dummies(row):
    if row['RACA_BENEFICIARIO_BOLSA_Amarela']:
        return 'Amarela'
    elif row['RACA_BENEFICIARIO_BOLSA_Branca']:
        return 'Branca'
    elif row['RACA_BENEFICIARIO_BOLSA_Ind√≠gena']:
        return 'Ind√≠gena'
    elif row['RACA_BENEFICIARIO_BOLSA_Parda']:
        return 'Parda'
    elif row['RACA_BENEFICIARIO_BOLSA_Preta']:
        return 'Preta'
    return 'N√£o Informada' # Fallback, though ideally all should be covered

def get_tipo_bolsa_from_dummies(row):
    if row['TIPO_BOLSA_BOLSA INTEGRAL']:
        return 'BOLSA INTEGRAL'
    elif row['TIPO_BOLSA_BOLSA PARCIAL 50%']:
        return 'BOLSA PARCIAL 50%'
    return 'N√£o Definido' # Fallback if neither is true

df_temp_for_crosstab = df_prouni.copy() # Work on a copy

df_temp_for_crosstab['RACA_BENEFICIARIO_BOLSA_RECONSTRUCTED'] = df_temp_for_crosstab.apply(get_race_from_dummies, axis=1)
df_temp_for_crosstab['TIPO_BOLSA_RECONSTRUCTED'] = df_temp_for_crosstab.apply(get_tipo_bolsa_from_dummies, axis=1)

tabela_contigencia = pd.crosstab(
    df_temp_for_crosstab['RACA_BENEFICIARIO_BOLSA_RECONSTRUCTED'],
    df_temp_for_crosstab['TIPO_BOLSA_RECONSTRUCTED'],
    margins=True,
    normalize = 'index'
)

print("Tabela de associa√ß√£o")

print((tabela_contigencia * 100).round(2).astype(str) + '%')

"""8. Redu√ß√£o de Dimensionalidade

"""

df_prouni.info()

def categorizar_curso(curso):
    curso = str(curso).upper()

    if 'MEDICINA' in curso or 'ENFERMAGEM' in curso or 'FISIOTERAPIA' in curso or 'ODONTOLOGIA' in curso or 'PSICOLOGIA' in curso or 'FARM√ÅCIA' in curso or 'BIOLOGIA' in curso or 'CI√äNCIAS BIOL√ìGICAS' in curso:
        return 'Sa√∫de'

    elif 'ENGENHARIA' in curso or 'AN√ÅLISE' in curso or 'SISTEMAS' in curso or 'CI√äNCIA DA COMPUTA√á√ÉO' in curso or 'TI' in curso or 'F√çSICA' in curso or 'MATEM√ÅTICA' in curso or 'ARQUITETURA' in curso or 'DESIGN' in curso:
        return 'Exatas e Tecnologia'

    elif 'DIREITO' in curso or 'HIST√ìRIA' in curso or 'PEDAGOGIA' in curso or 'LETRAS' in curso or 'SERVI√áO SOCIAL' in curso or 'COMUNICA√á√ÉO' in curso or 'JORNALISMO' in curso or 'TURISMO' in curso or 'GASTRONOMIA' in curso:
        return 'Humanas e Educa√ß√£o'

    elif 'ADMINISTRA√á√ÉO' in curso or 'CONT√ÅBEIS' in curso or 'ECONOMIA' in curso or 'MARKETING' in curso or 'COM√âRCIO' in curso or 'LOG√çSTICA' in curso or 'GEST√ÉO' in curso:
        return 'Neg√≥cios e Sociais'

    else:
        return 'Outros'

# Create a copy to avoid SettingWithCopyWarning
df_prouni = df_prouni.copy()
df_prouni['AREA_CURSO'] = df_prouni['NOME_CURSO_BOLSA'].apply(categorizar_curso)


distribuicao_area = df_prouni['AREA_CURSO'].value_counts().sort_index()

plt.figure(figsize=(8, 8))
plt.pie(
    distribuicao_area.values,
    labels=distribuicao_area.index,
    autopct='%1.1f%%',
    startangle=90,
    colors=sns.color_palette('pastel'),
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'}
)

plt.title("Distribui√ß√£o de Bolsas por √Årea de Conhecimento", fontsize=16, pad=20)
plt.axis('equal')
plt.tight_layout()
plt.show()

"""9. Identifica√ß√£o de Padr√µes

"""

df_prouni.info()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ASSUM√á√ÉO: O DataFrame 'df_prouni' (com a coluna AREA_CURSO e as colunas TIPO_BOLSA bin√°rias) est√° carregado.

def gerar_heatmap_acesso_bolsa(df_prouni: pd.DataFrame):
    """
    Gera a tabela de conting√™ncia e um Heatmap para visualizar a
    associa√ß√£o entre a √Årea do Curso e o Tipo de Bolsa (Integral vs. Parcial).
    """

    # 1. DEFINIR COLUNAS
    coluna_area = 'AREA_CURSO'
    coluna_integral = 'TIPO_BOLSA_BOLSA INTEGRAL'
    coluna_parcial = 'TIPO_BOLSA_BOLSA PARCIAL 50%'

    # 2. C√ÅLCULO DA TABELA DE CONTING√äNCIA (Usando .sum() nas colunas bin√°rias)
    # Agrupa por √Årea do Curso e soma as ocorr√™ncias de cada tipo de bolsa (Integral e Parcial).
    contingency_counts = df_prouni.groupby(coluna_area)[[coluna_integral, coluna_parcial]].sum()

    # 3. NORMALIZA√á√ÉO (Para obter a PROPOR√á√ÉO por √Årea do Curso)
    # axis=1 normaliza por LINHA (propor√ß√£o de cada tipo de bolsa DENTRO daquela √Årea)
    contingency_acesso = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)

    # 4. EXIBI√á√ÉO DA TABELA FORMATADA
    print("\nAssocia√ß√£o: √Årea de Curso vs. Tipo de Bolsa (Distribui√ß√£o de Benef√≠cio por √Årea):")
    # Adicionando uma coluna 'Total' para fins de verifica√ß√£o visual
    contingency_acesso['Total'] = contingency_acesso.sum(axis=1)

    print((contingency_acesso * 100).round(2).astype(str) + '%')

    # 5. GERA√á√ÉO DO HEATMAP

    # Remove a coluna 'Total' para o Heatmap (opcional)
    data_heatmap = contingency_acesso.drop(columns=['Total'])

    plt.figure(figsize=(12, 8))

    # Configura√ß√£o do Heatmap:
    # 'annot=True' mostra o valor dentro da c√©lula.
    # 'fmt=".1%"' formata o valor como porcentagem com 1 casa decimal.
    sns.heatmap(
        data_heatmap,
        annot=True,
        fmt=".1%",
        cmap="RdPu",
        linewidths=.5,
        linecolor='black'
    )

    plt.title('Acesso: Propor√ß√£o do Tipo de Bolsa por √Årea de Curso', fontsize=16)
    plt.ylabel('√Årea do Curso', fontsize=12)
    plt.xlabel('Tipo de Bolsa', fontsize=12)
    plt.yticks(rotation=0) # Rota√ß√£o 0 para melhor leitura dos nomes dos cursos
    plt.show()

# ==============================================================================
# EXECU√á√ÉO (Exemplo no Notebook)
# ==============================================================================

# Assumindo que o DataFrame 'df_prouni' est√° pronto:
gerar_heatmap_acesso_bolsa(df_prouni)

"""10. Documenta√ß√£o e Comunica√ß√£o

"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

def gerar_grafico_acesso_bolsa(df: pd.DataFrame):
    """
    Gera um gr√°fico de barras horizontais empilhadas mostrando a propor√ß√£o
    do Tipo de Bolsa (Integral vs. Parcial) em cada √Årea de Curso.
    """
    print("Gerando Gr√°fico de Acesso vs. Tipo de Benef√≠cio...")

    # 1. DEFINIR COLUNAS (Nomes corrigidos ap√≥s One-Hot Encoding)
    coluna_area = 'AREA_CURSO'
    coluna_integral = 'TIPO_BOLSA_BOLSA INTEGRAL'
    coluna_parcial = 'TIPO_BOLSA_BOLSA PARCIAL 50%'

    # 2. C√ÅLCULO DA PROPOR√á√ÉO (Substituindo pd.crosstab)
    # Agrupa por √Årea e soma as ocorr√™ncias de cada tipo de bolsa
    contingency_counts = df.groupby(coluna_area)[[coluna_integral, coluna_parcial]].sum()

    # Normaliza por linha (axis=1) para obter a propor√ß√£o dentro de cada √°rea de curso
    contingency_acesso = contingency_counts.div(contingency_counts.sum(axis=1), axis=0)

    # 3. ORDENA√á√ÉO (Mantendo a l√≥gica original do c√≥digo)
    # Ordena a tabela pela primeira coluna ('TIPO_BOLSA_BOLSA INTEGRAL') em ordem crescente
    coluna_ordenacao = contingency_acesso.columns[0]
    contigencia_ordenada = contingency_acesso.sort_values(by=coluna_ordenacao, ascending=True)

    # 4. GERA√á√ÉO DO GR√ÅFICO DE BARRAS EMPILHADAS

    plt.figure(figsize=(12, 7))

    ax = contigencia_ordenada.plot(
        kind='barh',
        stacked=True,
        figsize=(12, 7),
        # Corrigindo os nomes das colunas da legenda (opcional, mas recomendado)
        legend=False, # Desabilita a legenda autom√°tica para customizar
        color=['#1f77b4', '#ff7f0e']
    )

    # 5. CONFIGURA√á√ïES E ANOTA√á√ïES

    # Customiza a legenda (Nome amig√°vel)
    handles, labels = ax.get_legend_handles_labels()
    # Mapeia os nomes bin√°rios para nomes de bolsa mais leg√≠veis
    rotulos_amigaveis = ['Bolsa Integral', 'Bolsa Parcial 50%']

    plt.legend(
        handles,
        rotulos_amigaveis,
        title='Tipo de Bolsa',
        bbox_to_anchor=(1.05, 1),
        loc='upper left'
    )

    plt.title('Rela√ß√£o de Acesso vs. Tipo de Benef√≠cio (Propor√ß√£o de Bolsa por √Årea de Curso)', fontsize=16)
    plt.xlabel('Propor√ß√£o de Bolsas', fontsize=14)
    plt.ylabel('√Årea de Curso', fontsize=14)
    plt.xticks(rotation=0)

    # Adicionar porcentagens no centro das barras
    for container in ax.containers:
        # Pega a largura (propor√ß√£o) da barra para formatar como porcentagem
        labels = [f'{v.get_width()*100:.1f}%' if v.get_width() > 0.05 else '' for v in container]
        ax.bar_label(container, labels=labels, label_type='center', fontsize=10, color='white', fontweight='bold')

    plt.grid(axis='x', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()

# ==============================================================================
# EXECU√á√ÉO (Exemplo)
# ==============================================================================

# Assumindo que o DataFrame 'df' est√° pronto:
gerar_grafico_acesso_bolsa(df_prouni)

"""Exporta√ß√£o:"""

df_prouni.to_csv('df_prouni_limpo.csv', index=False)

"""# Treinamento"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('df_prouni_limpo.csv')

"""# Balanceado classes"""

df['TIPO_BOLSA_BOLSA INTEGRAL'].value_counts()

coluna_classe = 'TIPO_BOLSA_BOLSA INTEGRAL'

df_minoritaria = df[df[coluna_classe] == False]

# A classe 'True' √© a MAJORIT√ÅRIA (a ser reduzida)
df_majoritaria = df[df[coluna_classe] == True]

# Descobrir o tamanho da classe minorit√°ria (nosso alvo)
n_alvo = len(df_minoritaria)

# 3. APLICAR UNDERSAMPLING na CLASSE MAJORIT√ÅRIA
print(f"Reduzindo a classe Majorit√°ria de {len(df_majoritaria)} para {n_alvo} amostras...")

# Usar a fun√ß√£o sample()
df_majoritaria_undersampled = df_majoritaria.sample(
    n=n_alvo,
    random_state=42, # Garante que a amostragem seja reproduz√≠vel
    replace=False    # N√£o permite que o mesmo registro seja selecionado mais de uma vez
)

# 4. JUNTAR E VERIFICAR
df_balanceado = pd.concat([df_minoritaria, df_majoritaria_undersampled])

print("\nüéâ Balanceamento Conclu√≠do!")
print(f"Tamanho total do DataFrame Balanceado: {len(df_balanceado)}")

# Verificar a distribui√ß√£o final
distribuicao_final = df_balanceado[coluna_classe].value_counts()
print("\nDistribui√ß√£o Final:")
print(distribuicao_final)

"""# Treinamento

Defini√ß√£o de dados de entrada
"""

from sklearn.model_selection import train_test_split
import pandas as pd

def dividir_dados(entrada: pd.DataFrame, saida: pd.Series, test_size: float = 0.3, random_state: int = 42):
    """
    Divide o conjunto de dados (entrada e saida) em conjuntos de treinamento e teste.
    """
    print(f"Dividindo dados em Treinamento ({1 - test_size:.0%} da base) e Teste ({test_size:.0%} da base)...")

    entrada_treino, entrada_teste, saida_treino, saida_teste = train_test_split(
        entrada,
        saida,
        test_size=test_size,
        random_state=random_state,
        stratify=saida
    )

    print(f"Total de amostras de Treinamento (70%): {len(entrada_treino):,}")
    print(f"Total de amostras de Teste (30%): {len(entrada_teste):,}")
    print("\nDivis√£o conclu√≠da com sucesso!")

    return entrada_treino, entrada_teste, saida_treino, saida_teste

saida = df_prouni['TIPO_BOLSA_BOLSA INTEGRAL']
print("Vari√°vel de Sa√≠da (y) definida como 'TIPO_BOLSA_BOLSA INTEGRAL'.")


# Colunas categ√≥ricas que precisam ser one-hot encoded para o modelo
colunas_para_encodar_agora = [
    'MODALIDADE_ENSINO_BOLSA',
    'TURNO_CURSO',
    'BENEFICIARIO_DEFICIENTE_FISICO',
    'REGIAO',
    'AREA_CURSO'
]

df_prouni_encoded = pd.get_dummies(df_prouni, columns=colunas_para_encodar_agora, drop_first=True)

print(f"Colunas {', '.join(colunas_para_encodar_agora)} foram codificadas.")


colunas_para_remover = [
    'TIPO_BOLSA_BOLSA INTEGRAL',
    'TIPO_BOLSA_BOLSA PARCIAL 50%',
    'NOME_IES_BOLSA',
    'NOME_CURSO_BOLSA',
    'MUNICIPIO',
    'UF_BENEFICIARIO_BOLSA'
]

entrada = df_prouni_encoded.drop(columns=colunas_para_remover, errors='ignore')
print("Vari√°vel de Entrada (X) definida. Colunas de texto e redundantes removidas.")
print(f"N√∫mero de features (colunas em X): {entrada.shape[1]}")



entrada_treino, entrada_teste, saida_treino, saida_teste = dividir_dados(
    entrada=entrada,
    saida=saida,
    test_size=0.3,
    random_state=42
)

from sklearn.preprocessing import StandardScaler
import pandas as pd

coluna_numerica = ['IDADE_BENEFICIARIO']

scaler = StandardScaler()

# Fit on X_train_res and transform X_train_res, X_val, and X_test
# Make a copy to avoid SettingWithCopyWarning
X_train_scaled = X_train.copy()
X_val_scaled = X_val.copy()
X_test_scaled = X_test.copy()

X_train_scaled[coluna_numerica] = scaler.fit_transform(X_train_scaled[coluna_numerica])
X_val_scaled[coluna_numerica] = scaler.transform(X_val_scaled[coluna_numerica])
X_test_scaled[coluna_numerica] = scaler.transform(X_test_scaled[coluna_numerica])

print("StandardScaler aplicado com sucesso √† 'IDADE_BENEFICIARIO'.")
print("Os novos DataFrames escalados para treino, valida√ß√£o e teste s√£o: 'X_train_scaled', 'X_val_scaled' e 'X_test_scaled'.")

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay

# Fun√ß√£o para treinar e testar os modelos
def treinar_modelo(model):
    model.fit(entrada_treino,saida_treino)
    ypred=model.predict(entrada_teste)
    print(f"{accuracy_score(saida_teste,ypred)*100:.2f}\n\n{confusion_matrix(saida_teste,ypred)}\n\n{classification_report(saida_teste,ypred)}")
    ConfusionMatrixDisplay.from_estimator(model, entrada_teste, saida_teste)
    plt.show()

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5)
treinar_modelo(knn)

"""Regress√£o Log√≠stica"""

from sklearn.linear_model import LogisticRegression

modelo_regressao = LogisticRegression(random_state=42, solver='liblinear')

treinar_modelo(modelo_regressao)

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier

modelo_rf = RandomForestClassifier(random_state=42)

param_grid = {
    'n_estimators': [100, 250],
    'max_depth': [8, 15, 25, None],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

random_search = RandomizedSearchCV(
    estimator=modelo_rf,
    param_distributions=param_grid,
    n_iter=20,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

# Executar o Fit
random_search.fit(entrada_treino, saida_treino)

"""Rede neural"""

from sklearn.neural_network import MLPClassifier

modelo_nn = MLPClassifier(hidden_layer_sizes=(50,),max_iter=500, random_state=42)

treinar_modelo(modelo_nn)

import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.under_sampling import RandomUnderSampler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report, confusion_matrix

# ==============================================================================
# 1. CARREGAMENTO DOS DADOS
# ==============================================================================
# Usando o arquivo CSV gerado anteriormente e o DataFrame 'df_prouni'
# O nome do arquivo deve ser 'df_prouni_limpo.csv'
df = pd.read_csv('df_prouni_limpo.csv')

# ------------------------------------------------------------------------------
# 2. DEFINI√á√ÉO DE FEATURES (X) E TARGET (y)
# ------------------------------------------------------------------------------
# A coluna target √© 'TIPO_BOLSA_BOLSA INTEGRAL'
TARGET_COL = 'TIPO_BOLSA_BOLSA INTEGRAL'

# Colunas categ√≥ricas que precisam ser one-hot encoded para o modelo
colunas_para_encodar_agora = [
    'MODALIDADE_ENSINO_BOLSA',
    'TURNO_CURSO',
    'BENEFICIARIO_DEFICIENTE_FISICO',
    'REGIAO',
    'AREA_CURSO'
]

# Aplicar get_dummies ao DataFrame 'df' carregado localmente
df_encoded = pd.get_dummies(df, columns=colunas_para_encodar_agora, drop_first=True)

print(f"Colunas {', '.join(colunas_para_encodar_agora)} foram codificadas.")

# Definir a vari√°vel de sa√≠da (y) e as colunas a serem removidas de X
y = df_encoded[TARGET_COL]

colunas_para_remover = [
    'TIPO_BOLSA_BOLSA INTEGRAL',
    'TIPO_BOLSA_BOLSA PARCIAL 50%',
    'NOME_IES_BOLSA',
    'NOME_CURSO_BOLSA',
    'MUNICIPIO',
    'UF_BENEFICIARIO_BOLSA'
]

# As colunas originais que foram one-hot encoded j√° foram removidas por get_dummies.
# As novas colunas dummy (ex: 'MODALIDADE_ENSINO_BOLSA_Presencial') permanecer√£o em X.
# Remover apenas as colunas identificadas acima como n√£o features ou redundantes.
X = df_encoded.drop(columns=colunas_para_remover, errors='ignore')

print("Vari√°vel de Sa√≠da (y) definida como 'TIPO_BOLSA_BOLSA INTEGRAL'.")
print("Vari√°vel de Entrada (X) definida. Colunas de texto e redundantes removidas.")

# Ponto de checagem do n√∫mero de features para a camada de entrada
num_features = X.shape[1]
print(f"N√∫mero de features (colunas em X): {num_features}")

# ------------------------------------------------------------------------------
# 3. DIVIS√ÉO EM TREINO E TESTE (80/20)
# ------------------------------------------------------------------------------
X_train_full, X_test, y_train_full, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# ------------------------------------------------------------------------------
# 4. BALANCEAMENTO (APENAS NO CONJUNTO DE TREINO)
# Conforme seu relat√≥rio, voc√™ usou RandomUnderSampler.
# ------------------------------------------------------------------------------
print(f"Dados de Treino ANTES do balanceamento: {y_train_full.value_counts()}")
rus = RandomUnderSampler(random_state=42)
X_train_res, y_train_res = rus.fit_resample(X_train_full, y_train_full)
print(f"Dados de Treino DEPOIS do balanceamento: {y_train_res.value_counts()}")

# ------------------------------------------------------------------------------
# 5. DIVIS√ÉO DO TREINO EM TREINO e VALIDA√á√ÉO (para monitorar o NN)
# ------------------------------------------------------------------------------
# 80% dos dados balanceados v√£o para TREINO (NN) e 20% para VALIDA√á√ÉO
X_train, X_val, y_train, y_val = train_test_split(
    X_train_res, y_train_res, test_size=0.2, random_state=42, stratify=y_train_res
)

# Ponto de checagem do n√∫mero de features para a camada de entrada
num_features = X_train.shape[1]
print(f"\nN√∫mero de Features (Colunas de Entrada) para o NN: {num_features}")

# ==============================================================================
# 6. DEFINI√á√ÉO DA ARQUITETURA DA REDE NEURAL
# ==============================================================================
model = Sequential([
    # Camada de Entrada / Primeira Camada Oculta: Usa o n√∫mero de features
    Dense(128, activation='relu', input_shape=(num_features,)),
    Dropout(0.2), # Dropout para regulariza√ß√£o

    # Camadas Ocultas
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),

    # Camada de Sa√≠da: 1 neur√¥nio e Sigmoid para Classifica√ß√£o Bin√°ria (0 ou 1)
    Dense(1, activation='sigmoid')
])

# 7. COMPILA√á√ÉO DO MODELO
model.compile(optimizer='adam',
              loss='binary_crossentropy', # Perda ideal para classifica√ß√£o bin√°ria
              metrics=['accuracy'])

print("\n--- Resumo da Arquitetura da Rede Neural ---")
model.summary()

# ==============================================================================
# 8. TREINAMENTO COM EARLY STOPPING
# ==============================================================================
# Early Stopping: Para o treino se a perda de valida√ß√£o n√£o melhorar ap√≥s 15 √©pocas
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True,
    verbose=1
)

print("\n--- Iniciando o Treinamento da Rede Neural ---")
history = model.fit(
    X_train_scaled.astype('float32'), y_train.astype('float32'),  # Use scaled X_train
    epochs=100,
    batch_size=64,
    validation_data=(X_val_scaled.astype('float32'), y_val.astype('float32')), # Use scaled X_val
    callbacks=[early_stop],
    verbose=1
)
print("--- Treinamento Conclu√≠do ---")

# ==============================================================================
# 9. AVALIA√á√ÉO FINAL NO CONJUNTO DE TESTE
# ==============================================================================

# Avaliar a Acur√°cia e Perda
loss, accuracy = model.evaluate(X_test_scaled.astype('float32'), y_test.astype(int).astype('float32'), verbose=0) # Use scaled X_test
print(f"\n--- Resultados no Conjunto de Teste ---")
print(f"Perda Final (Binary Crossentropy): {loss:.4f}")
print(f"Acur√°cia Final: {accuracy:.4f}")

# Fazer Previs√µes (Probabilidades)
y_pred_proba = model.predict(X_test_scaled.astype('float32')) # Use scaled X_test

# Converter Probabilidades em Classes (0 ou 1) usando threshold 0.5
y_pred_class = (y_pred_proba > 0.5).astype(int)

# Relat√≥rio de Classifica√ß√£o Detalhado
print("\n--- Relat√≥rio de Classifica√ß√£o (Precision, Recall, F1-Score) ---")
print(classification_report(y_test, y_pred_class))

# Matriz de Confus√£o
print("\n--- Matriz de Confus√£o ---")
# Linhas: Valores Reais (True); Colunas: Valores Preditos (Predicted)
# Onde: [TN, FP]
#       [FN, TP]
print(confusion_matrix(y_test, y_pred_class))